[2021-10-29 18:54:27,079] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: first_python_dag.print_the_context manual__2021-10-29T18:54:25.307489+00:00 [queued]>
[2021-10-29 18:54:27,083] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: first_python_dag.print_the_context manual__2021-10-29T18:54:25.307489+00:00 [queued]>
[2021-10-29 18:54:27,084] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2021-10-29 18:54:27,085] {taskinstance.py:1242} INFO - Starting attempt 1 of 1
[2021-10-29 18:54:27,085] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2021-10-29 18:54:27,090] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): print_the_context> on 2021-10-29 18:54:25.307489+00:00
[2021-10-29 18:54:27,092] {standard_task_runner.py:52} INFO - Started process 50 to run task
[2021-10-29 18:54:27,095] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'first_python_dag', 'print_the_context', 'manual__2021-10-29T18:54:25.307489+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/first_python_dag.py', '--cfg-path', '/tmp/tmpi1bn4cyd', '--error-file', '/tmp/tmpp9_dfa9t']
[2021-10-29 18:54:27,096] {standard_task_runner.py:77} INFO - Job 2: Subtask print_the_context
[2021-10-29 18:54:27,113] {logging_mixin.py:109} INFO - Running <TaskInstance: first_python_dag.print_the_context manual__2021-10-29T18:54:25.307489+00:00 [running]> on host 49d47df7fb89
[2021-10-29 18:54:27,127] {taskinstance.py:1412} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=first_python_dag
AIRFLOW_CTX_TASK_ID=print_the_context
AIRFLOW_CTX_EXECUTION_DATE=2021-10-29T18:54:25.307489+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2021-10-29T18:54:25.307489+00:00
[2021-10-29 18:54:27,135] {python.py:152} INFO - Done. Returned value was:    col1  col2
0     1     3
1     2     4
[2021-10-29 18:54:27,138] {xcom.py:332} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config.
[2021-10-29 18:54:27,139] {taskinstance.py:1686} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 1502, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 2231, in xcom_push
    XCom.set(
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/xcom.py", line 99, in set
    value = XCom.serialize_value(value)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/xcom.py", line 330, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/lib/python3.8/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2021-10-29 18:54:27,142] {taskinstance.py:1270} INFO - Marking task as FAILED. dag_id=first_python_dag, task_id=print_the_context, execution_date=20211029T185425, start_date=20211029T185427, end_date=20211029T185427
[2021-10-29 18:54:27,148] {standard_task_runner.py:88} ERROR - Failed to execute job 2 for task print_the_context
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/usr/local/lib/python3.8/dist-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/usr/local/lib/python3.8/dist-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/usr/local/lib/python3.8/dist-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 1502, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/taskinstance.py", line 2231, in xcom_push
    XCom.set(
  File "/usr/local/lib/python3.8/dist-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/xcom.py", line 99, in set
    value = XCom.serialize_value(value)
  File "/usr/local/lib/python3.8/dist-packages/airflow/models/xcom.py", line 330, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/lib/python3.8/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2021-10-29 18:54:27,194] {local_task_job.py:154} INFO - Task exited with return code 1
[2021-10-29 18:54:27,201] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
